{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## はじめに\n",
    "\n",
    "Googleが提供を開始したディープラーニング用のライブラリTensorFlowについて、忘備録ついでに投稿させてもらいます。TensorFlowはTutorialの解説が詳しいので、それを日本語にしてみました。\n",
    "・TensorFlowについて-> http://www.tensorflow.org/\n",
    "・今回の翻訳原本 ->  http://www.tensorflow.org/tutorials/mnist/pros/index.md\n",
    "生粋の日本人なので違和感のある翻訳や誤訳もあり得ますので自己責任でお願いします。\n",
    "[参考 【TensorFlowのTutorialをざっくり日本語訳していく】1. MNIST For ML begginers ]\n",
    "\n",
    "今回のTutorialは岡谷さんの著書「深層学習」の第6章を読みながら見るとわかりやすいでしょう。本記事ではストライドやパディングなど専門用語も出てくるので参考資料は必須です。\n",
    "\n",
    "\n",
    "それでは、今回作成するモデルは畳み込みニューラルネットワーク(CNN)と言われるモデルです。\n",
    "\n",
    "## MNISTデータの読み込み\n",
    "*ここらへんは飛ばし気味でいくので前回の記事を参考にしてください*\n",
    "\n",
    "MNISTデータセットを取得するスクリプトを実行します。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "\n",
    "import numpy\n",
    "from six.moves import xrange  # pylint: disable=redefined-builtin\n",
    "\n",
    "from tensorflow.contrib.learn.python.learn.datasets import base\n",
    "from tensorflow.python.framework import dtypes\n",
    "from tensorflow.python.platform import gfile\n",
    "\n",
    "SOURCE_URL = 'http://yann.lecun.com/exdb/mnist/'\n",
    "\n",
    "\n",
    "def _read32(bytestream):\n",
    "  dt = numpy.dtype(numpy.uint32).newbyteorder('>')\n",
    "  return numpy.frombuffer(bytestream.read(4), dtype=dt)[0]\n",
    "\n",
    "\n",
    "def extract_images(filename):\n",
    "  \"\"\"Extract the images into a 4D uint8 numpy array [index, y, x, depth].\"\"\"\n",
    "  print('Extracting', filename)\n",
    "  with gfile.Open(filename, 'rb') as f, gzip.GzipFile(fileobj=f) as bytestream:\n",
    "    magic = _read32(bytestream)\n",
    "    if magic != 2051:\n",
    "      raise ValueError('Invalid magic number %d in MNIST image file: %s' %\n",
    "                       (magic, filename))\n",
    "    num_images = _read32(bytestream)\n",
    "    rows = _read32(bytestream)\n",
    "    cols = _read32(bytestream)\n",
    "    buf = bytestream.read(rows * cols * num_images)\n",
    "    data = numpy.frombuffer(buf, dtype=numpy.uint8)\n",
    "    data = data.reshape(num_images, rows, cols, 1)\n",
    "    return data\n",
    "\n",
    "\n",
    "def dense_to_one_hot(labels_dense, num_classes):\n",
    "  \"\"\"Convert class labels from scalars to one-hot vectors.\"\"\"\n",
    "  num_labels = labels_dense.shape[0]\n",
    "  index_offset = numpy.arange(num_labels) * num_classes\n",
    "  labels_one_hot = numpy.zeros((num_labels, num_classes))\n",
    "  labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n",
    "  return labels_one_hot\n",
    "\n",
    "\n",
    "def extract_labels(filename, one_hot=False, num_classes=10):\n",
    "  \"\"\"Extract the labels into a 1D uint8 numpy array [index].\"\"\"\n",
    "  print('Extracting', filename)\n",
    "  with gfile.Open(filename, 'rb') as f, gzip.GzipFile(fileobj=f) as bytestream:\n",
    "    magic = _read32(bytestream)\n",
    "    if magic != 2049:\n",
    "      raise ValueError('Invalid magic number %d in MNIST label file: %s' %\n",
    "                       (magic, filename))\n",
    "    num_items = _read32(bytestream)\n",
    "    buf = bytestream.read(num_items)\n",
    "    labels = numpy.frombuffer(buf, dtype=numpy.uint8)\n",
    "    if one_hot:\n",
    "      return dense_to_one_hot(labels, num_classes)\n",
    "    return labels\n",
    "\n",
    "\n",
    "class DataSet(object):\n",
    "\n",
    "  def __init__(self,\n",
    "               images,\n",
    "               labels,\n",
    "               fake_data=False,\n",
    "               one_hot=False,\n",
    "               dtype=dtypes.float32,\n",
    "               reshape=True):\n",
    "    \"\"\"Construct a DataSet.\n",
    "    one_hot arg is used only if fake_data is true.  `dtype` can be either\n",
    "    `uint8` to leave the input as `[0, 255]`, or `float32` to rescale into\n",
    "    `[0, 1]`.\n",
    "    \"\"\"\n",
    "    dtype = dtypes.as_dtype(dtype).base_dtype\n",
    "    if dtype not in (dtypes.uint8, dtypes.float32):\n",
    "      raise TypeError('Invalid image dtype %r, expected uint8 or float32' %\n",
    "                      dtype)\n",
    "    if fake_data:\n",
    "      self._num_examples = 10000\n",
    "      self.one_hot = one_hot\n",
    "    else:\n",
    "      assert images.shape[0] == labels.shape[0], (\n",
    "          'images.shape: %s labels.shape: %s' % (images.shape, labels.shape))\n",
    "      self._num_examples = images.shape[0]\n",
    "\n",
    "      # Convert shape from [num examples, rows, columns, depth]\n",
    "      # to [num examples, rows*columns] (assuming depth == 1)\n",
    "      if reshape:\n",
    "        assert images.shape[3] == 1\n",
    "        images = images.reshape(images.shape[0],\n",
    "                                images.shape[1] * images.shape[2])\n",
    "      if dtype == dtypes.float32:\n",
    "        # Convert from [0, 255] -> [0.0, 1.0].\n",
    "        images = images.astype(numpy.float32)\n",
    "        images = numpy.multiply(images, 1.0 / 255.0)\n",
    "    self._images = images\n",
    "    self._labels = labels\n",
    "    self._epochs_completed = 0\n",
    "    self._index_in_epoch = 0\n",
    "\n",
    "  @property\n",
    "  def images(self):\n",
    "    return self._images\n",
    "\n",
    "  @property\n",
    "  def labels(self):\n",
    "    return self._labels\n",
    "\n",
    "  @property\n",
    "  def num_examples(self):\n",
    "    return self._num_examples\n",
    "\n",
    "  @property\n",
    "  def epochs_completed(self):\n",
    "    return self._epochs_completed\n",
    "\n",
    "  def next_batch(self, batch_size, fake_data=False):\n",
    "    \"\"\"Return the next `batch_size` examples from this data set.\"\"\"\n",
    "    if fake_data:\n",
    "      fake_image = [1] * 784\n",
    "      if self.one_hot:\n",
    "        fake_label = [1] + [0] * 9\n",
    "      else:\n",
    "        fake_label = 0\n",
    "      return [fake_image for _ in xrange(batch_size)], [\n",
    "          fake_label for _ in xrange(batch_size)\n",
    "      ]\n",
    "    start = self._index_in_epoch\n",
    "    self._index_in_epoch += batch_size\n",
    "    if self._index_in_epoch > self._num_examples:\n",
    "      # Finished epoch\n",
    "      self._epochs_completed += 1\n",
    "      # Shuffle the data\n",
    "      perm = numpy.arange(self._num_examples)\n",
    "      numpy.random.shuffle(perm)\n",
    "      self._images = self._images[perm]\n",
    "      self._labels = self._labels[perm]\n",
    "      # Start next epoch\n",
    "      start = 0\n",
    "      self._index_in_epoch = batch_size\n",
    "      assert batch_size <= self._num_examples\n",
    "    end = self._index_in_epoch\n",
    "    return self._images[start:end], self._labels[start:end]\n",
    "\n",
    "\n",
    "def read_data_sets(train_dir,\n",
    "                   fake_data=False,\n",
    "                   one_hot=False,\n",
    "                   dtype=dtypes.float32,\n",
    "                   reshape=True):\n",
    "  if fake_data:\n",
    "\n",
    "    def fake():\n",
    "      return DataSet([], [], fake_data=True, one_hot=one_hot, dtype=dtype)\n",
    "\n",
    "    train = fake()\n",
    "    validation = fake()\n",
    "    test = fake()\n",
    "    return base.Datasets(train=train, validation=validation, test=test)\n",
    "\n",
    "  TRAIN_IMAGES = 'train-images-idx3-ubyte.gz'\n",
    "  TRAIN_LABELS = 'train-labels-idx1-ubyte.gz'\n",
    "  TEST_IMAGES = 't10k-images-idx3-ubyte.gz'\n",
    "  TEST_LABELS = 't10k-labels-idx1-ubyte.gz'\n",
    "  VALIDATION_SIZE = 5000\n",
    "\n",
    "  local_file = base.maybe_download(TRAIN_IMAGES, train_dir,\n",
    "                                   SOURCE_URL + TRAIN_IMAGES)\n",
    "  train_images = extract_images(local_file)\n",
    "\n",
    "  local_file = base.maybe_download(TRAIN_LABELS, train_dir,\n",
    "                                   SOURCE_URL + TRAIN_LABELS)\n",
    "  train_labels = extract_labels(local_file, one_hot=one_hot)\n",
    "\n",
    "  local_file = base.maybe_download(TEST_IMAGES, train_dir,\n",
    "                                   SOURCE_URL + TEST_IMAGES)\n",
    "  test_images = extract_images(local_file)\n",
    "\n",
    "  local_file = base.maybe_download(TEST_LABELS, train_dir,\n",
    "                                   SOURCE_URL + TEST_LABELS)\n",
    "  test_labels = extract_labels(local_file, one_hot=one_hot)\n",
    "\n",
    "  validation_images = train_images[:VALIDATION_SIZE]\n",
    "  validation_labels = train_labels[:VALIDATION_SIZE]\n",
    "  train_images = train_images[VALIDATION_SIZE:]\n",
    "  train_labels = train_labels[VALIDATION_SIZE:]\n",
    "\n",
    "  train = DataSet(train_images, train_labels, dtype=dtype, reshape=reshape)\n",
    "  validation = DataSet(validation_images,\n",
    "                       validation_labels,\n",
    "                       dtype=dtype,\n",
    "                       reshape=reshape)\n",
    "  test = DataSet(test_images, test_labels, dtype=dtype, reshape=reshape)\n",
    "\n",
    "  return base.Datasets(train=train, validation=validation, test=test)\n",
    "\n",
    "\n",
    "def load_mnist(train_dir='MNIST-data'):\n",
    "  return read_data_sets(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "('Extracting', 'MNIST_data/train-images-idx3-ubyte.gz')\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "('Extracting', 'MNIST_data/train-labels-idx1-ubyte.gz')\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "('Extracting', 'MNIST_data/t10k-images-idx3-ubyte.gz')\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "('Extracting', 'MNIST_data/t10k-labels-idx1-ubyte.gz')\n"
     ]
    }
   ],
   "source": [
    "mnist = read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## TensorFlowのInteractiveSessionを開始\n",
    "TensorFlowは自身の計算を行うにあたり高度に効率的なC++バックエンドを活用します。このバックエンドへの結合(connection)をsessionと呼びます。TensorFlowの一般的な使い方は、まずグラフを作り、そしてsessionを実行する、というものです。\n",
    "\n",
    "しかしここでは便利なInteractiveSessionクラスーーこれは、ユーザーがどのようにコードを書くかについて、TensorFlowの柔軟性をより高めるものですーーを用います。これはiPythonのように、インタラクティブに作業をする時に役に立ちます。もしInteractiveSessionを使わなかった場合、ユーザーはsessionを開始する前にcomputation graphの全体を作り上げ、その後にgraphを実行する必要があります。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Computation Graph\n",
    "TensorFlowは、単一の重い命令をpythonの外で独立に実行する代わりに、相互に作用する命令全体をpythonの外で実行するための\"グラフ(graph)\"を記述することが可能です。これと似た手法はTheanoやTorchでも用いられています。\n",
    "\n",
    "従ってpythonコードの役割は、このexternal computational graphを構築し、そのgraphのどの部分を実行するか命令を下すことです。\n",
    "\n",
    "## Softmax Regression Modelの構築\n",
    "*前回の記事参照*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9092\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(\"float\", shape=[None, 784])\n",
    "y_ = tf.placeholder(\"float\", shape=[None, 10])\n",
    "\n",
    "W = tf.Variable(tf.zeros([784,10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "y = tf.nn.softmax(tf.matmul(x,W) + b)\n",
    "\n",
    "cross_entropy = -tf.reduce_sum(y_*tf.log(y))\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n",
    "\n",
    "for i in range(1000):\n",
    "  batch = mnist.train.next_batch(50)\n",
    "  train_step.run(feed_dict={x: batch[0], y_: batch[1]})\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "print accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 多層畳み込みネットワークの構築\n",
    "MNIST正答率91%ではembarrassingly badです。\n",
    "小さなConvolutional neural networkを構築し、99.2%の正答率を目指します。\n",
    "\n",
    "### Weightの初期化\n",
    "CNNを作るために、たくさんのweightとbiasesを作る必要があります。一般的には、対称性を破りゼロ勾配を防ぐために小さな\u000fノイズを添えてweightsを初期化するべきでしょう。今回はReLUニューロンを用いているので、わずかな正の値を持った初期biasで各素子を初期化する(\"死んだニューロン\"を避けるため)こともまた良い手法です。モデルを作るたびにこれを繰り返す代わりに、それを実行してくれる便利な2つの関数を作りましょう。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 畳み込みとプーリング\n",
    "\n",
    "TensorFlowは畳み込みとプーリングにおいて多大な柔軟性を与えてくれます。どのように境界を扱おうか？スライドはどれくらいをとろうか？今回の例では最もありきたりなものを使いましょう。このCNNは1のストライド(stride)をとり、ゼロパディングを使うので、出力は入力と同じサイズになります。プーリングは2*2ブロックにまたがるplain old max poolingです。コードを綺麗に保つために、これらの操作を関数にまとめましょう。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def conv2d(x,W):\n",
    "   return tf.nn.conv2d(x,W,strides=[1,1,1,1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "   return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1],padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 第1層目の畳み込み層\n",
    "すでに私たちは第1層目を実行することができます。まず畳み込みがあり、そのあとにくるのはmax poolingです。畳み込みは5x5のパッチそれぞれに対し、32の特徴を計算します(*5x5のパッチに対して32個の数字を返すということかな？)。そのweightテンソルの形は[5,5,1,32]です。最初の2つの次元はパッチサイズで、その次が入力チャネルの数、そして最後はアウトプットのチャネル数です。またbiasベクトルも用意します。そのベクトルの要素はそれぞれ、各出力チャネルに与えられます。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W_conv1 = weight_variable([5,5,1,32])\n",
    "b_conv1 = bias_variable([32])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "この層に合わせるために、まずはxベクトルを4次元のテンソルに整形します。第二・第三次元は画像の幅と高さに対応し、第四次元は色のチャンネルに対応します。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_image = tf.reshape(x,[-1,28,28,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "それではx_imageをweightテンソルで畳み込み、biasを足し、ReLU関数に代入し、max poolを取りましょう\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1)+b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 第2層目の畳み込み層\n",
    "第2層目では64の特徴量を、5x5のパッチについて取ります。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W_conv2 = weight_variable([5,5,32,64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2)+b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 全結合層\n",
    "今や画像サイズは7x7まで落ちています。これに、1024のニューロン素子を持った全結合層を加え、画像全体を処理させます。プーリング層からのテンソル\n",
    "量をベクトルのバッチに変換し、weight行列と掛け合わせ、biasを加え、ReLUに代入します。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W_fc1 = weight_variable([7*7*64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1)+b_fc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### ドロップアウト\n",
    "過学習の問題を避ける為、読み出し層の前にドロップアウトを適用します。ドロップアウトの間にニューロンの出力を保存するために確率分布を用い、その確率分布のためのPlaceholderを用意します。(よく意味がわからない)\n",
    "これによってトレーニングのあいあはドロップアウトをONにし、テストの間はOFFにする、ということができます。TensorFlowのtf.nn.dropout命令は、ニューロン出力をマスキングすることに加え、自動的にスケーリングも行ってくれます(..?)これによってドロップアウトは追加的なスケーリングなしにただ機能するのです。(..??)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(\"float\")\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 読み出し層\n",
    "最後に、Softmax層を加えます。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W_fc2 = weight_variable([1024,10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "y_conv = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2)+b_fc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## トレーニングとモデルの評価\n",
    "上述の単層Softmaxネットワークとの違いは以下のとおりです。\n",
    "・Steepest Gradient Optimizerをより洗練されたADAM optimizerで置き換えています。\n",
    "・ドロップアウトのレートを操作するために追加的なパラメーターkeep_probをfeed_dictに加えています。\n",
    "・トレーニングの100回ごとにログを残すようにしています。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.06\n"
     ]
    }
   ],
   "source": [
    "cross_entropy = -tf.reduce_sum(y_*tf.log(y_conv))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "sess.run(tf.initialize_all_variables())\n",
    "for i in range(20000):\n",
    "  batch = mnist.train.next_batch(50)\n",
    "  if i%100 == 0:\n",
    "    train_accuracy = accuracy.eval(feed_dict={\n",
    "        x:batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "    print \"step %d, training accuracy %g\"%(i, train_accuracy)\n",
    "  train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "\n",
    "print \"test accuracy %g\"%accuracy.eval(feed_dict={\n",
    "    x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
